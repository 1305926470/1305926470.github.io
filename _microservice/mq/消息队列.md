---
layout: single
title:  "消息队列"
date:   2020-01-25 11:22:26 +0800
permalink: /microservice/mq/mq
toc: true
toc_sticky: true
---

# 消息队列

[TOC]

## 常用消息队列对比
### RabbitMQ
老牌儿消息队列，轻量级、迅捷，容易部署和使用，使用最广泛的队列之一。RabbitMQ 一个比较有特色的功能是支持非常灵活的路由配置，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个 Exchange 模块，即交换机。
Exchange 模块的作用和交换机也非常相似，根据配置的路由规则将生产者发出的消息分发到不同的队列中。路由的规则也非常灵活，甚至你可以自己来实现路由规则。基于这个 Exchange，可以产生很多的玩儿法，如果你正好需要这个功能，RabbitMQ 是个不错的选择。
exchange是AMQP协议中定义的，RabbitMQ是AMQP的一个实现。

**不足**

1. RabbitMQ 对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。
2. RabbitMQ 的性能相比其他几个消息队列是最差的。大概每秒钟可以处理几万到十几万条消息。这个性能也足够支撑绝大多数的应用场景了。若对象性能要求很高，建议考虑其他消息队列。

### RocketMQ
RocketMQ 是阿里开源的消息队列产品，阿里内部也是使用 RocketMQ 作为支撑其业务的消息队列，经历过多次“双十一”考验，它的性能、稳定性和可靠性都是值得信赖的。是优秀的国产消息队列。
稳定可靠，有不少涉及金融类的系统选择使用RocketMQ。
`RocketMQ 对在线业务的响应时延做了很多的优化`，大多数情况下可以做到毫秒级的响应，如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ。
RocketMQ 的性能比 RabbitMQ 要高一个数量级，每秒钟大概能处理几十万条消息。
RocketMQ Java 语言开发，有非常活跃的中文社区。在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹。

### Kafka
Kafka 最初的设计目的是用于处理海量的日志。Kafka 已经发展为一个非常成熟的消息队列产品，无论在数据可靠性、稳定性和功能特性等方面都可以满足绝大多数场景的需求。
Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域，几乎所有的相关开源软件系统都会优先支持 Kafka。
Kafka 设计上大量使用了`批量处理和异步`的思想，这种设计使得 Kafka 能做到超高的性能。Kafka 的性能，尤其是异步收发的性能，是三者中最好的，但与 RocketMQ 并没有量级上的差异，大约每秒钟可以处理几十万条消息。
Kafka 这种异步批量的设计带来的问题是，它的同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，`Kafka 不太适合在线业务场景`。

如今版本的Kafka是可以保证完全不丢消息的，丢消息已经是n年前很老的版本的事了。

### 其他
RocketMQ，RocketMQ，Kafka 算是消息队列中的第一梯队了。还有几个第二梯队的产品，如ActiveMQ，ZeroMQ，Pulsar等，它们没那么流行，都有其比较明显的短板。ActiveMQ 是最老牌的开源消息队列，与现代的消息队列存在明显的差距。不建议使用。

emq是专注于MQTT场景的一个消息队列，如果你的使用场景是连接海量的IoT设备，可以考虑。
如果是golang的技术栈，也不妨尝试下nsq。

### 选型

rabbitmq：
- 优点：轻量，迅捷，容易部署和使用，拥有灵活的路由配置，性能中规中矩
- 缺点：性能和吞吐量较差，不易进行二次开发

rocketmq：
- 优点：性能好，稳定可靠，有活跃的中文社区，特点响应快
- 缺点：兼容性较差，但随意影响力的扩大，该问题会有改善

kafka：
- 优点：拥有强大的性能及注重吞吐量，兼容性很好
- 缺点：由于“批处理和异步处理”或导致延迟比较高

pulsar：
- 采用存储和计算分离的设计，是消息队里产品中黑马，值得持续关注

方案选型：
1. 对消息队列功能和性能都没有很高的要求，只需要一个开箱即用易于维护的产品，建议使用 RabbitMQ。
2. 如果你的系统使用消息队列主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，那 RocketMQ 的低延迟和金融级的稳定性，你值得拥有。
3. 如果你需要处理海量的消息，收集日志、监控信息或是前端的埋点这类数据，或是你的应用场景大量使用了大数据、流计算相关的开源产品，那 Kafka 是最适合你的消息队列。
4. RocketMQ它的时延更小一些，而Kafka的吞吐量更高。

> 
`架构设计很多情况下是在做取舍和选择。`
好的架构不是设计出来的，而是演进出来的。

### 消息模型
#### 队列&主题
队列是先进先出（FIFO, First-In-First-Out）的线性表，在具体应用中通常用链表或者数组来实现。队列只允许在后端（称为 rear）进行插入操作，在前端（称为 front）进行删除操作。
如果有多个消费者接收同一个队列的消息，这些消费者之间实际上是竞争的关系，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。

在一些场景，需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，例如，对于一份订单数据，风控系统、分析系统、支付系统等都需要接收消息。这个时候，单个队列就满足不了需求。“发布—订阅” 可以有效的解决这个问题。

在`发布 - 订阅`模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。每份订阅中，订阅者都可以接收到主题的所有消息。

队列就是主题，并没有本质的区别。它们最大的区别其实就是，一份消息数据能不能被消费多次的问题。在这种发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样。

现代的消息队列产品使用的消息模型大多是这种发布 - 订阅模型，不过RabbitMQ有点例外。

### RabbitMQ 的消息模型
在RabbitMQ中，，生产者并不关心将消息发送给哪个队列，而是将消息发送给 Exchange，由 Exchange 上配置的策略来决定将消息投递到哪些队列中。同一份消息如果需要被多个消费者来消费，需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相地实现新发布 - 订阅模型中。

### RocketMQ Kafka 的消息模型
Kafka 的消息模型和 RocketMQ 是完全一样.
RocketMQ 使用的消息模型是标准的发布 - 订阅模型，

#### 避免消息丢失
几乎所有的消息队列产品都使用“请求 - 确认”机制，确保消息不会在传递过程中由于网络或服务器故障丢失。
生产端，如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；
在消费端，消费者在收到消息并完成自己的消费业务逻辑后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费。

确认机制很好地保证了消息传递过程中的可靠性，但是，引入这个机制在消费端带来了一个不小的问题。为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则违背了有序性这个原则。这样岂不是就变成了串行消费了吗？

#### 并发能力
**如何在有请求-确认，保证有序的情况下，提高消费能力?**
RocketMQ 在主题下面增加了队列的概念。通过多个队列来实现多实例并行生产和消费。需要注意的是，`RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的`。
订阅者的概念是通过`消费组`（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。
消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。如果一条消息被消费者 Consumer1 消费了，那同组的其他消费者就不会再收到这条消息。

#### Consumer Offset
在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，我们在使用消息队列的时候，丢消息的原因大多是由于消费位置处理不当导致的。

#### kafka
Kafka 的消息模型和 RocketMQ 是完全一样,生产消费过程中的确认机制，都完全适用于 Kafka。唯一的区别是，在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能是没有任何区别的。

RabbitMQ 采用的是队列模型，但是它一样可以实现发布 - 订阅的功能。RocketMQ 和 Kafka 采用的是发布 - 订阅模型，并且二者的消息模型是基本一致的。

## 消息队列中的“事务”

如何利用事务消息实现分布式事务？

消息队列中的“事务”，主要解决的是消息生产者和消息消费者的数据一致性问题。

很多场景下，我们“发消息”这个过程，目的往往是通知另外一个系统或者模块去更新数据。

### 分布式事务

mysql，oracle 等单体关系型数据库都完整的实现了 ACID事物特性，但是，对于分布式系统来说，严格的实现 ACID 这四个特性几乎是不可能的，或者说实现的代价太大，大到我们无法接受。

分布式事务就是要在分布式系统中的实现事务。在分布式系统中，在保证可用性和不严重牺牲性能的前提下，光是要实现数据的一致性就已经非常困难了，于是就有了比如顺序一致性、最终一致性等等。

显然实现严格的分布式事务是更加不可能完成的任务。所以，通常所说的分布式事务，是在分布式系统中事务的不完整实现。在不同的应用场景中，有不同的实现，目的都是通过一些妥协来解决实际问题。

在实际应用中，比较常见的分布式事务实现有 2PC（Two-phase Commit，也叫二阶段提交）、TCC(Try-Confirm-Cancel) 和事务消息。每一种实现都有其特定的使用场景，也有各自的问题，都不是完美的解决方案。

事务消息适用的场景主要是那些需要异步更新数据，并且对数据实时性要求不太高的场景。

### 消息队列是如何实现分布式事务的？

Kafka 和 RocketMQ 都提供了事务相关功能。

生产者发送一个“半消息”，这个半消息不是说消息内容不完整，它包含的内容就是完整的消息内容，半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。

半消息发送成功后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果决定提交或者回滚事务消息。如果订单创建成功，那就提交事务消息，如果订单创建失败，那就回滚事务消息，这样就基本实现了“要么都成功，要么都失败”的一致性要求。

如果在提交事务消息时失败了怎么办？对于这个问题，Kafka 和 RocketMQ 给出了 2 种不同的解决方案。

Kafka 的解决方案比较简单粗暴，直接抛出异常，让用户自行处理。我们可以在业务代码中反复重试提交，直到提交成功，或者删除之前创建的订单进行补偿。

**RocketMQ 中的分布式事务实现**，在 RocketMQ 中的事务实现中，增加了事务反查的机制来解决事务消息提交失败的问题。如果 Producer 也就是订单系统，在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer 上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。

为了支撑这个事务反查机制，我们的业务代码需要实现一个反查本地事务状态的接口，告知 RocketMQ 本地事务是成功还是失败。



## 学习消息队列

先不要太关注功能、API 和配置这些细节，在学习如何使用消息队列的过程中，要保持一定的高度来学习。

因为使用消息队列，大部分的难点在宏观架构层面，要解决这些难点，你需要掌握消息队列宏观层面上的实现原理和最佳实践，这样，无论你使用什么消息队列，都可以做到游刃有余。在选定了合适的消息队列产品，准备写代码之前，再去文档中查看这些细节都来得及。























