

[TOC]

## 内存重排

`内存排序`是指CPU访问主存时的顺序。可以是编译器在编译时产生，也可以是CPU在运行时产生。反映了内存操作重排序，乱序执行，从而充分利用不同内存的总线带宽。

现代处理器大都是乱序执行。因此需要内存屏障以确保多线程的同步。

没有依赖关系的内存操作实际会以随机的顺序执行，但对CPU-CPU的交互和I/O来说却是个问题。我们需要某种方式来指导编译器和CPU以约束执行顺序。

内存屏障就是这样一种干预手段。它们会给屏障两侧的内存操作加了顺序关系。

这种强制措施是很重要的，因为一个系统中，CPU和其它硬件可以使用各种技巧来提高性能，包括内存操作的重排、延迟和合并；预取；推测执行分支以及各种类型的缓存。内存屏障是用来禁用或抑制这些技巧的，使代码稳健地控制多个CPU和(或)设备的交互。



## 内存屏障

同步屏障(Barrier)是并行计算中的一种同步方法。对于一群进程或线程，程序中的一个同步屏障意味着任何线程/进程执行到此后必须等待，直到所有线程/进程都到达此点才可继续执行下文。

`内存屏障`（英语：Memory barrier）是一类`同步屏障`指令，它使得 CPU 或编译器在对内存进行操作的时候, 严格按照一定的顺序来执行, 也就是说在memory barrier 之前的指令和memory barrier之后的指令不会由于系统优化等原因而导致乱序，即在内存屏障前执行的操作一定会先于内存屏障后执行的操作。

大多数现代计算机为了提高性能而采取乱序执行，这使得内存屏障成为必须。

大多数处理器提供了内存屏障指令:

- 完全内存屏障(full memory barrier)保障了早于屏障的内存读写操作的结果提交到内存之后，再执行晚于屏障的读写操作。
- 内存读屏障(read memory barrier)仅确保了内存读操作；
- 内存写屏障(write memory barrier)仅保证了内存写操作。

语义上，内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。因此，对于敏感的程序块，写操作之后、读操作之前可以插入内存屏障。

内存屏障是底层原语，是`内存排序`的一部分，在不同架构体系结构差异较大。





## reference

[go runtime mbarrier](https://github.com/golang/go/blob/master/src/runtime/mbarrier.go)

[Memory Barriers: a Hardware View for Software Hackers](http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf)

[Linux内核的内存屏障](https://ifeve.com/linux-memory-barriers/)









